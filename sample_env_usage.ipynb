{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/sparse/lil.py:19: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _csparsetools\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:165: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._shortest_path import shortest_path, floyd_warshall, dijkstra,\\\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/_validation.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:167: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._traversal import breadth_first_order, depth_first_order, \\\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:169: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/sparse/csgraph/__init__.py:170: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._reordering import reverse_cuthill_mckee, maximum_bipartite_matching, \\\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/special/__init__.py:640: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ufuncs import *\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/linalg/basic.py:17: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._solve_toeplitz import levinson\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/linalg/__init__.py:207: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._decomp_update import *\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/special/_ellip_harm.py:7: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._ellip_harm_2 import _ellipsoid, _ellipsoid_norm\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/interpolate/_bsplines.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _bspl\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .ckdtree import *\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/spatial/__init__.py:96: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .qhull import *\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/spatial/_spherical_voronoi.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _voronoi\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/spatial/distance.py:122: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hausdorff\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/optimize/_trlib/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._trlib import TRLIBQuadraticSubproblem\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/optimize/_numdiff.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._group_columns import group_dense, group_sparse\n",
      "/u/ansarigh/miniconda2/lib/python2.7/site-packages/scipy/stats/_continuous_distns.py:18: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _stats\n"
     ]
    }
   ],
   "source": [
    "from environment import Environment\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file = 'parameters/parameters_simple_small.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = json.load(open(params_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished init: read data\n",
      "initialized read data\n",
      "PARAM:  num_timesteps ::  4\n",
      "PARAM:  state_dim ::  200\n",
      "PARAM:  glove_dir ::  /dccstor/cssblr/amrita/dialog_qa/CSQA_NPI_resources/\n",
      "PARAM:  print_valid_freq ::  1\n",
      "PARAM:  initial_epsilon ::  0.1\n",
      "PARAM:  vocab_file ::  ../../../../data/preprocessed_data_alltypes_100/train/vocab.pkl\n",
      "PARAM:  none_decay ::  1\n",
      "PARAM:  wikidata_dir ::  ../../../../wikidata_100/\n",
      "PARAM:  print_train_freq ::  1\n",
      "PARAM:  prune_beam_type_mismatch ::  1\n",
      "PARAM:  relaxed_reward_strict ::  False\n",
      "PARAM:  max_len ::  20\n",
      "PARAM:  epoch_for_biasing_program_sample_with_target ::  [30, 1000000]\n",
      "PARAM:  max_epochs ::  30\n",
      "PARAM:  train_mode ::  reinforce\n",
      "PARAM:  prog_key_dim ::  100\n",
      "PARAM:  var_key_dim ::  100\n",
      "PARAM:  train_data_file ::  ../../../../data/preprocessed_data_alltypes_100/train/maxnumvar3/\n",
      "PARAM:  train_freq ::  100\n",
      "PARAM:  dropout_keep_prob ::  0.8\n",
      "PARAM:  concat_query_npistate ::  True\n",
      "PARAM:  Rate_Entropy ::  0.0005\n",
      "PARAM:  questype_wise_batching ::  True\n",
      "PARAM:  wikidata_embed_dim ::  100\n",
      "PARAM:  question_type ::  simple\n",
      "PARAM:  params_turn_on_after ::  epoch\n",
      "PARAM:  num_variables_to_sample ::  4\n",
      "PARAM:  print ::  False\n",
      "PARAM:  reward_function ::  jaccard\n",
      "PARAM:  valid_data_file ::  ../../../../data/preprocessed_data_alltypes_100/train/maxnumvar3/\n",
      "PARAM:  dont_look_back_attention ::  False\n",
      "PARAM:  reward_from_model ::  False\n",
      "PARAM:  prune_after_epoch_no. ::  [3, 100]\n",
      "PARAM:  terminate_prog ::  True\n",
      "PARAM:  model_dir ::  model\n",
      "PARAM:  max_num_var ::  3\n",
      "PARAM:  var_embed_dim ::  200\n",
      "PARAM:  valid_freq ::  100\n",
      "PARAM:  learning_rate ::  1e-05\n",
      "PARAM:  unused_var_penalize_after_epoch ::  [30, 1000000]\n",
      "PARAM:  batch_size ::  5\n",
      "PARAM:  model_embed_dim ::  100\n",
      "PARAM:  explore ::  [-1, -1]\n",
      "PARAM:  prog_embed_dim ::  200\n",
      "PARAM:  relaxed_reward_till_epoch ::  [-1, -1]\n",
      "PARAM:  epoch_for_biasing_program_sample_with_last_variable ::  [30, 100000]\n",
      "PARAM:  Debug ::  0\n",
      "PARAM:  parallel ::  0\n",
      "PARAM:  use_var_key_as_onehot ::  False\n",
      "PARAM:  env_dim ::  200\n",
      "PARAM:  text_embed_dim ::  300\n",
      "PARAM:  use_key_as_onehot ::  False\n",
      "PARAM:  lr_intermideate_reward ::  0\n",
      "PARAM:  epoch_for_feasible_program_at_last_step ::  [5, 1000]\n",
      "PARAM:  argtype_embed_dim ::  200\n",
      "PARAM:  sample_with ::  argmax\n",
      "PARAM:  change_train_mode_after_epoch ::  5\n",
      "PARAM:  normalize_length ::  1\n",
      "PARAM:  beam_size ::  10\n",
      "PARAM:  hidden_dim ::  200\n",
      "PARAM:  query_attention ::  True\n",
      "PARAM:  test_data_file ::  ../../../../data/preprocessed_data_alltypes_100/train/maxnumvar3/\n",
      "PARAM:  model_file ::  best_model\n",
      "PARAM:  num_programs_to_sample ::  10\n",
      "loaded params \n",
      "Time taken to load wikidata  29.6029059887 seconds\n",
      "initialized interpreter\n"
     ]
    }
   ],
   "source": [
    "env = Environment(param,'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "['Which award was received by Gerold Spath ?', 'Which gene encodes OTU domain-containing protein 6A ?', 'What was the sport that Wayne Chism was a part of ?', 'What represents the molecular function of hydrolase    SCO0790 ?', 'What encodes poly(A) polymerase    RP015 ?'] \n",
      "\n",
      "Entities:\n",
      "[[u'Q123491', None, None], [u'Q21985941', None, None], [u'Q4018594', None, None], [u'Q27754451', None, None], [u'Q23448980', None, None]] \n",
      "\n",
      "Types:\n",
      "[[u'Q618779', None, None], [u'Q863908', None, None], [u'Q349', None, None], [u'Q44424', None, None], [u'Q863908', None, None]] \n",
      "\n",
      "Relations:\n",
      "[[u'P166', None, None], [u'P702', None, None], [u'P641', None, None], [u'P680', None, None], [u'P702', None, None]] \n",
      "\n",
      "Ints: [[None, None, None], [None, None, None], [None, None, None], [None, None, None], [None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "questions, entities, types, relations, ints = env.fetch_batch()\n",
    "print 'Questions:\\n', questions, '\\n\\n', 'Entities:\\n', entities, '\\n\\n', 'Types:\\n', types, '\\n\\n', 'Relations:\\n', relations, '\\n\\n', 'Ints:', ints\n",
    "# this function can be used to fetch a random batch of \n",
    "# queries along with entities, types, relations #\n",
    "# and integers associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for enacting an action use the step function.\n",
    "# the step function takes in as input an array of programs (shape batch_size x beam_size)\n",
    "# sample program\n",
    "with open('new_a_seq.pkl','r') as fp:\n",
    "    program_batch = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "keys in program dictionary: ['argument_type', 'program_type', 'variable_value_table', 'target_type', 'target_table_index', 'argument_table_index']\n"
     ]
    }
   ],
   "source": [
    "print len(program_batch)\n",
    "print len(program_batch[0])\n",
    "print 'keys in program dictionary:', program_batch[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'argument_type': [array([1, 2, 3], dtype=int32), array([0, 0, 0], dtype=int32), array([0, 0, 0], dtype=int32), array([0, 0, 0], dtype=int32)], 'program_type': [1, 0, 20, 20], 'variable_value_table': array([[None, None, None],\n",
      "       [u'Q22259773', None, None],\n",
      "       [u'P106', None, None],\n",
      "       [u'Q12737077', None, None],\n",
      "       [None, None, None],\n",
      "       [None, None, None],\n",
      "       [set([u'Q937857']), set([u'Q937857']), None],\n",
      "       [None, None, None],\n",
      "       [None, None, None]], dtype=object), 'target_type': [6, 0, 0, 0], 'target_table_index': [0, 0, 0, 0], 'argument_table_index': [array([0, 0, 0], dtype=int32), array([0, 0, 0], dtype=int32), array([0, 0, 0], dtype=int32), array([0, 0, 0], dtype=int32)]}\n"
     ]
    }
   ],
   "source": [
    "print program_batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read_data.py:407: RuntimeWarning: divide by zero encountered in divide\n",
      "  atten = np.divide(atten, num_ints)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch id  0 :: Query ::  What notable work was done by Lawrence Weiner ?\n",
      "beam id 0\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 1\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 2\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 3\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 4\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 5\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 6\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 7\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 8\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 9\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) set_oper_ints( set(0),set(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.1  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "batch id  1 :: Query ::  Which language can Valeria Pujol i Bosch understand ?\n",
      "beam id 0\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) select_oper_min( map2(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "FLAG: Sampling_from_empty_table\n",
      "beam id 1\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) select_oper_max( map2(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "FLAG: Sampling_from_empty_table\n",
      "beam id 2\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "found intermediate reward of  0.5  at timestep  2\n",
      "beam id 3\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "FLAG: Sampling_from_empty_table\n",
      "beam id 4\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "found intermediate reward of  0.5  at timestep  2\n",
      "beam id 5\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "FLAG: Sampling_from_empty_table\n",
      "beam id 6\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "FLAG: Sampling_from_empty_table\n",
      "beam id 7\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "beam id 8\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "beam id 9\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) map_oper_diff( map1(0),map1(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "FLAG: executed_line_output_none\n",
      "FLAG: Sampling_from_empty_table\n",
      "batch id  2 :: Query ::  Which sex does Li Guang belong to ?\n",
      "beam id 0\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 1\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 2\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 3\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 4\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 5\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 6\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 7\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 8\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 9\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "batch id  3 :: Query ::  Which name is associated with Lee Gye-deok ?\n",
      "beam id 0\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) gen_set( entity(0),relation(0),type(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  2\n",
      "beam id 1\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) select_oper_min( map2(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 0.0  flag =  0.0  relaxed_reward = 0\n",
      "beam id 2\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  2\n",
      "beam id 3\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  2\n",
      "beam id 4\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) select_oper_max( map2(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 0.0  flag =  0.0  relaxed_reward = 0\n",
      "beam id 5\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer= map2 gold_answer= set  reward = -1.0  relaxed_reward = -1\n",
      "beam id 6\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer= map2 gold_answer= set  reward = -1.0  relaxed_reward = -1\n",
      "beam id 7\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) map_oper_count( map1(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer= map2 gold_answer= set  reward = -1.0  relaxed_reward = -1\n",
      "beam id 8\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer= map1 gold_answer= set  reward = -1.0  relaxed_reward = -1\n",
      "beam id 9\n",
      "per_step_programs [ gen_map1( type(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  2\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer= map1 gold_answer= set  reward = -1.0  relaxed_reward = -1\n",
      "batch id  4 :: Query ::  What can be considered as category for Agathonas Iakovidis ?\n",
      "beam id 0\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 1\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 2\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 3\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 4\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 5\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 6\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 7\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 8\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) none( none(0),none(0),none(0) ) terminate( none(0),none(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.0  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n",
      "beam id 9\n",
      "per_step_programs [ gen_set( entity(0),relation(0),type(0) ) none( none(0),none(0),none(0) ) set_oper_count( set(0),none(0),none(0) ) set_oper_ints( set(0),set(0),none(0) ) ]\n",
      "number of entities:  1\n",
      "number of relations:  1\n",
      "number of types:  1\n",
      "number of ints:  0\n",
      "In calculate reward: predicted_answer=set, gold_answer= set  reward = 1.0  flag =  0.1  relaxed_reward = 0\n",
      "found intermediate reward of  1.0  at timestep  1\n"
     ]
    }
   ],
   "source": [
    "# enaction of sample program_batch\n",
    "rewards = env.step(program_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   1.   1.   1.   1.   1.   1.   1.   1.   0.9]\n",
      " [-1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1. ]\n",
      " [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      " [ 1.   0.   1.   1.   0.  -1.  -1.  -1.  -1.  -1. ]\n",
      " [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   0.9]]\n"
     ]
    }
   ],
   "source": [
    "print rewards\n",
    "# step function returns the reward for each program in the batchxbeam input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': 5,\n",
       " 'entity': 1,\n",
       " 'int': 4,\n",
       " 'map1': 7,\n",
       " 'map2': 8,\n",
       " 'none': 0,\n",
       " 'relation': 2,\n",
       " 'set': 6,\n",
       " 'type': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.argument_vocabulary()\n",
    "# returns mapping of arguments to corresponding integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gen_map1': ['type', 'relation', 'type'],\n",
       " 'gen_set': ['entity', 'relation', 'type'],\n",
       " 'map_oper_count': ['map1'],\n",
       " 'map_oper_diff': ['map1', 'map1'],\n",
       " 'map_oper_ints': ['map1', 'map1'],\n",
       " 'map_oper_union': ['map1', 'map1'],\n",
       " 'select_oper_approx': ['map2', 'int'],\n",
       " 'select_oper_atleast': ['map2', 'int'],\n",
       " 'select_oper_atmost': ['map2', 'int'],\n",
       " 'select_oper_equal': ['map2', 'int'],\n",
       " 'select_oper_less': ['map2', 'int'],\n",
       " 'select_oper_max': ['map2'],\n",
       " 'select_oper_min': ['map2'],\n",
       " 'select_oper_more': ['map2', 'int'],\n",
       " 'set_oper_count': ['set'],\n",
       " 'set_oper_diff': ['set', 'set'],\n",
       " 'set_oper_ints': ['set', 'set'],\n",
       " 'set_oper_union': ['set', 'set'],\n",
       " 'verify': ['entity', 'relation', 'entity']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_verbose, mapping_index = env.operator_to_argument_type_mapping()\n",
    "# returns mapping containing which operator needs which type of argument\n",
    "mapping_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gen_map1': 2,\n",
       " 'gen_set': 1,\n",
       " 'map_oper_count': 8,\n",
       " 'map_oper_diff': 11,\n",
       " 'map_oper_ints': 10,\n",
       " 'map_oper_union': 9,\n",
       " 'none': 0,\n",
       " 'select_oper_approx': 19,\n",
       " 'select_oper_atleast': 14,\n",
       " 'select_oper_atmost': 15,\n",
       " 'select_oper_equal': 18,\n",
       " 'select_oper_less': 17,\n",
       " 'select_oper_max': 12,\n",
       " 'select_oper_min': 13,\n",
       " 'select_oper_more': 16,\n",
       " 'set_oper_count': 4,\n",
       " 'set_oper_diff': 7,\n",
       " 'set_oper_ints': 6,\n",
       " 'set_oper_union': 5,\n",
       " 'terminate': 20,\n",
       " 'verify': 3}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.operator_type_vocabulary()\n",
    "# returns mapping of opertors to corresponding integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
